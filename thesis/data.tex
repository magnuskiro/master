\chapter{Data, retrieval and structure}
% The data. What used, how and why. Acquired data how and from where. 

This section describes the data sources, methods for acquisition, and the
structure of the used data. \ref{data:tweets} describes twitter and the mined
tweets. \ref{data:dictionaries} describe the different lists of words used in
the classification process. And last the finance data is described in
\ref{data:finance}.

For each section the structure, characteristics, metadata and usage are
described. 

#TODO chapter outline
%

% The section about twitter and tweets 
\section{Tweets}\label{data:tweets}
#TODO introduce and describe a tweet. \\
Please note that Twitter's search service and, by extension, the Search API is
not meant to be an exhaustive source of Tweets. Not all Tweets will be indexed
or made available via the search interface. 
%

\subsection{Tweet Structure}
#TODO describe the json structure and the contents.\\
There are a lot of meta data in the tweets. In fact most of the data in a tweet
object is not the tweet text itself.

Tweets directly usable in python, vie dictionary and literal eval thingy. 
%

% data acquisition
\subsection{Twitter API}
#TODO describe the API\\
#TODO api setup\\
#TODO API simple use.\\
#TODO API restrictions\\

Description of the api and which options we have with the search. 

Simple guide to access the twitter api:  http://datascienceandprogramming.wordpress.com/2013/05/14/twitter-api/

This is a list of all the API calls that is used in this thesis.
% 

\paragraph{Search} 
\hspace{0pt}\\

\begin{itemize}
\item[q] A UTF-8, URL-encoded search query of 1,000 characters maximum, including
operators. Queries may additionally be limited by complexity.

\item[count] The amount of tweets acquired in each request. Standard = 15, max
= 100. 

\end{itemize}
%

\paragraph{Mining optimization}
\hspace{0pt}\\

#TODO -rt, searching vs generator\\ 
%

\subsection{Tweet sets}
#TODO manual classification\\
#TODO search terms\\
#TODO limitations\\

\subsection{Biased Data}
#TODO write this section\\
Due to the necessity of a search term in the query, we only get tweets that are
related to the given terms.

Further more the datasets of manually labeled tweets are biased based on my
personal opinion and state of mind in the moment of classification.  

\subsection{Trend Data}
#TODO Briefly describe the mining and API shortcomings for this particular
use.\\
#TODO describe the trend search terms: '\_search-terms'\\
#TODO write shortcomings of the search terms. \\
#TODO Describe the tweet data sets and sorting. \\ 

\subsection{Problems, Shortcomings, and Possible Improvements}
The potential problems and shortcomings of the data. 

#TODO retweets.\\ 
#TODO search terms.\\
#TODO finance vs not finance.\\

% describing the dictionaries used in the classification of tweets. 
\section{Dictionaries}\label{data:dictionaries}
#TODO introduction to dictionaries, of corpus whatever the name. \\
#TODO the purpose of the dictionary\\
#TODO use of the dictionaries. \\
%

\subsection{Downloaded Dictionaries}
#TODO describe the distinctions of dl dict

\paragraph{Obama}
\hspace{0pt}\\
#TODO describe obama dictionary.\\ 

\paragraph{Loughran & McDonald}
\hspace{0pt}\\
#TODO describe this dictionary
Tim Loughran and Bill McDonald has a set of dictionaries available from the
websites of University of Notre Dame \footnote{#TODO fiks tekst: nd.edu:
\url{http://www3.nd.edu/~mcdonald/Word_Lists.html}}. 

List of Dictionaries:
\begin{itemize}
    \item negative words
General list of negative words. No particular category. Used for basic   
    \item positive words
This dictionary contains a small set of positive words. There are no general
category for the words. The words are not directly related to finance. 
    \item Uncertainty words
    \item litigious words
    \item modal words strong
    \item modal words weak
\end{itemize}
%

\subsection{Compiled Dictionaries}
The compiled dictionaries are based on two manually labeled tweet sets. My own,
the kiro dataset, and the obama tweet set.
 
#TODO ref the used datasets.\\ 

Details about the process of manually classifying tweets can be found in section
\ref{sentiment:manual_classification}.

#TODO describe the dictionary compilation.\\


List of dictionaries:

#TODO describe the different dictionaries\\ 
\begin{itemize}
    \item Obama original, Monogram 
	\subitem description

    \item LoughranMcDonald, Monogram 
	\subitem description

    \item Obama original and LoughranMcDonald, Monogram, combined
	\subitem description

    \item Kiro, Monogram, self compiled 
	\subitem description

    \item Obama, Monogram, self compiled 
	\subitem description

    \item Kiro, Bigram, self compiled 
	\subitem description

    \item Obama, Bigram, self compiled 
	\subitem description

    \item Kiro, Trigram, self compiled 
	\subitem description

    \item Obama, Trigram, self compiled 
	\subitem description
	\label{data:dictionary_list}
\end{itemize}
%

\subsection{Error analysis, removal of duplicate words}
When creating the different dictionaries we remove duplicates from the positive
and negative dictionary set. Words that are present in both the positive and
negative dictionary is removed. By doing this we remove words that has no
significance in the classification. But we also risk removing words with
significance.

When looking at the duplicate words from the monogram dictionary based on the
kiro dataset we found some errors.
As a selection of words found, we have \textit{dangerous, bad, go, inc, let, up, or, need, good, if, no, are, and, of, on, the,
is, as}.
Here we can see that the words \textit{good} and \textit{bad} are represented.
Which is not good. By removing the words from the dictionaries we have removed
significant words in further classification, thus reducing correctness of the
algorithm. This is one of the drawbacks of the monogram dictionaries.

When looking at the removed duplicate words for bigram and trigrams we found no
indication of the same problem. As the uniqueness of bigrams and trigrams are a
lot greater we end up with very few duplicates and only duplicates that has no
significance to the over all classification. Although we might have other
unknown problems.  

Most stop words and other insignificant words are removed with the removal of
duplicate words. The same thing cannot be said about the bigram and trigram
dictionaries. There we have no stop words present in themselves, but they are
frequently part of other terms. For further improvements of classification with
word counting and dictionary quality we should remove
stop words, such as \textit{as, is, on, off, and, or} etc, from the
tweet/sentence before creating bi- and trigrams.     
%

% The financial data used in the thesis. 
\section{Finance Data}\label{data:finance}
#TODO obtaining the data(potential mining operations)
#TODO about the dataset, csv
#TODO potential problems 
%

